{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA: result table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_filenames = []\n",
    "algo_additionals = []\n",
    "algo_dims = []\n",
    "algo_labels = []\n",
    "algo_dividers = []\n",
    "\n",
    "def add_algo(filename, add, label, dim=512):\n",
    "    algo_filenames.append(filename)\n",
    "    algo_additionals.append(add)\n",
    "    algo_dims.append(dim)\n",
    "    algo_labels.append(label)\n",
    "    \n",
    "    \n",
    "def add_divider():\n",
    "    algo_dividers.append(len(algo_filenames))\n",
    "\n",
    "add_algo(\"flow\", \"april\", r\"\\af{}\", 512)\n",
    "add_algo(\"pie\", \"april\", r\"\\pie{}\", 512)\n",
    "add_algo(\"pie\", \"may\", r\"\\pie{} ($n = 128$)\", 128)\n",
    "add_algo(\"mf\", \"april\", r\"\\mf{}\", 512)\n",
    "add_algo(\"mf\", \"may\", r\"\\mf{} ($n = 128$)\", 128)\n",
    "add_algo(\"emf\", \"april\", r\"\\mfe{}\", 512)\n",
    "add_algo(\"emf\", \"may\", r\"\\mfe{} ($n = 128$)\", 128)\n",
    "\n",
    "n_algos = len(algo_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../data/results/pie_128_celeba_may_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/pie_128_celeba_may_run1_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/pie_128_celeba_may_run2_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/mf_128_celeba_may_run1_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/mf_128_celeba_may_run2_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/emf_128_celeba_may_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/emf_128_celeba_may_run1_model_x_reco_test.npy'\n",
      "[Errno 2] No such file or directory: '../data/results/emf_128_celeba_may_run2_model_x_reco_test.npy'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(tag, shape, numpyfy=True, chains=1, result_dir=\"../data/results\"):\n",
    "    all_results = []\n",
    "    \n",
    "    for algo_filename, algo_add, algo_dim in zip(algo_filenames, algo_additionals, algo_dims):\n",
    "        algo_results = []\n",
    "            \n",
    "        for run in range(n_runs):\n",
    "            run_str = \"\" if run == 0 else \"_run{}\".format(run)\n",
    "\n",
    "            try:\n",
    "                this_result = np.load(\n",
    "                    f\"{result_dir}/{algo_filename}_{algo_dim}_celeba_{algo_add}{run_str}_{tag}.npy\"\n",
    "                )\n",
    "                if (not numpyfy) or (shape is None) or np.product(this_result.shape) == np.product(shape):\n",
    "                    algo_results.append(this_result.reshape(shape))\n",
    "                else:\n",
    "                    algo_results.append(np.nan*np.ones(shape))\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                if \"reco_test\" in tag: print(e)\n",
    "                if shape is None:\n",
    "                    algo_results.append(None)\n",
    "                else:\n",
    "                    algo_results.append(np.nan*np.ones(shape))\n",
    "            \n",
    "        all_results.append(algo_results)\n",
    "    \n",
    "    if numpyfy:\n",
    "        all_results = np.array(all_results, dtype=np.float)\n",
    "        all_results = all_results.reshape([all_results.shape[0], n_runs] + list(shape))\n",
    "        \n",
    "    return all_results\n",
    "\n",
    "\n",
    "model_test_reco_xs = load(\"model_x_reco_test\", (100, 3, 64, 64))\n",
    "model_test_reco_errors = load(\"model_reco_error_test\", (100,))\n",
    "model_gen_fids = load(\"samples_fid\", (1,)).squeeze()\n",
    "model_gen_fids.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_reco_error = 10000.\n",
    "model_mean_reco_errors = np.mean(np.clip(model_test_reco_errors, 0., max_reco_error), axis=2)\n",
    "model_mean_reco_errors.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute mean and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_err_without_outliers(data, remove=0):\n",
    "    shape = list(data.shape)[:-1]\n",
    "    data.reshape((-1, data.shape[-1]))\n",
    "    \n",
    "    means, errors = [], []\n",
    "    \n",
    "    for data_ in data:\n",
    "        data_ = data_[np.isfinite(data_)]\n",
    "        if not len(data_) > 0:\n",
    "            means.append(np.nan)\n",
    "            errors.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        if len(data_) > 2*remove + 1:\n",
    "            for _ in range(remove):\n",
    "                data_ = np.delete(data_, np.argmin(data_))\n",
    "                data_ = np.delete(data_, np.argmax(data_))\n",
    "\n",
    "        means.append(np.mean(data_))\n",
    "        errors.append(np.std(data_) / len(data_)**0.5)\n",
    "        \n",
    "    return np.array(means).reshape(shape), np.array(errors).reshape(shape)\n",
    "    \n",
    "    \n",
    "model_fid_mean, model_fid_std = mean_err_without_outliers(model_gen_fids)\n",
    "model_reco_error_mean, model_reco_error_std = mean_err_without_outliers(model_mean_reco_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\af{}\n",
      "\\mf{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannbrehmer/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "best_fid = -1\n",
    "best_reco = -1\n",
    "\n",
    "best_fid = np.nanargmin(model_fid_mean)\n",
    "print(algo_labels[best_fid])\n",
    "\n",
    "best_reco = np.nanargmin(np.where(model_reco_error_mean > 1., model_reco_error_mean, np.nan))\n",
    "print(algo_labels[best_reco])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(\n",
    "    l_label=max([len(l) for l in algo_labels]), l_means=(5,4), l_errs=(3,3), latex=False, after_decs=(1,0), labels=[\"FID\", \"RE\"]\n",
    "):\n",
    "    # Number of digits\n",
    "    l_results = np.array(l_means) + 2 + np.array(l_errs)\n",
    "    l_total = l_label + 1 + np.sum(3 + l_results)\n",
    "        \n",
    "    # Divider\n",
    "    col_divider = \"&\" if latex else \"|\"\n",
    "    line_end = r\"\\\\\" if latex else \"\"\n",
    "    block_divider = r\"\\midrule\" if latex else \"-\"*l_total\n",
    "    \n",
    "    # Number formatting\n",
    "    def _f(val, err, after_dec, best, l_mean, l_err):\n",
    "        l_result = l_mean + 2 + l_err\n",
    "        empty_result = \"\" if latex else \" \"*(l_result + 1)\n",
    "        \n",
    "        if not np.any(np.isfinite(val)):\n",
    "            return empty_result\n",
    "        \n",
    "        result = \"{:>{}.{}f}\".format(val, l_mean, after_dec)\n",
    "        if latex and best:\n",
    "            result = r\"\\textbf{\" + result + \"}\"\n",
    "            \n",
    "        if latex:\n",
    "            err_str = str.rjust(\"{:.{}f}\".format(err, after_dec), l_err).replace(\" \", r\"\\hphantom{0}\")\n",
    "            result += r\"\\;\\textcolor{darkgray}{$\\pm$\\;\" + err_str + \"}\"\n",
    "        else:\n",
    "            err_str = \"({:>{}.{}f})\".format(err, l_err, after_dec)\n",
    "            result += err_str\n",
    "            \n",
    "        result += \"*\" if not latex and best else \" \"\n",
    "        \n",
    "        if latex:\n",
    "            result = result.replace(\"-\", \"$-{}$\")\n",
    "            result = result.replace(\"darkgray\", \"dark-gray\")\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    # Header\n",
    "    print(f\"{'':<{l_label}.{l_label}s} {col_divider} {labels[0]:>{l_results[0]}.{l_results[0]}s} {col_divider} {labels[1]:>{l_results[1]}.{l_results[1]}s} {line_end}\")\n",
    "    print(block_divider)\n",
    "\n",
    "    # Iterate over methods\n",
    "    for i, (label, fid, fid_err, reco, reco_err) in enumerate(zip(\n",
    "        algo_labels, model_fid_mean, model_fid_std, model_reco_error_mean, model_reco_error_std\n",
    "    )):\n",
    "        # Divider\n",
    "        if i in algo_dividers:\n",
    "            print(block_divider)\n",
    "            \n",
    "        # Print results\n",
    "        print(\n",
    "            f\"{label:<{l_label}.{l_label}s} {col_divider} \"\n",
    "            + f\"{_f(fid, fid_err, after_decs[0], i==best_fid, l_means[0], l_errs[0]):s}{col_divider} \"\n",
    "            + f\"{_f(reco, reco_err, after_decs[1], i==best_reco, l_means[1], l_errs[1]):s} {line_end}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   |        FID |        RE \n",
      "--------------------------------------------\n",
      "\\af{}              |  33.6(0.2)*|    0(  0)  \n",
      "\\pie{}             |  75.7(5.1) | 6970( 97)  \n",
      "\\pie{} ($n = 128$) |            |            \n",
      "\\mf{}              |  37.4(0.2) |  830(  5)* \n",
      "\\mf{} ($n = 128$)  |  37.2(0.0) | 1645(  0)  \n",
      "\\mfe{}             |  35.8(0.4) |  991(  4)  \n",
      "\\mfe{} ($n = 128$) |            |            \n"
     ]
    }
   ],
   "source": [
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   &        FID &        RE \\\\\n",
      "\\midrule\n",
      "\\af{}              & \\textbf{ 33.6}\\;\\textcolor{dark-gray}{$\\pm$\\;0.2} &    0\\;\\textcolor{dark-gray}{$\\pm$\\;\\hphantom{0}\\hphantom{0}0}  \\\\\n",
      "\\pie{}             &  75.7\\;\\textcolor{dark-gray}{$\\pm$\\;5.1} & 6970\\;\\textcolor{dark-gray}{$\\pm$\\;\\hphantom{0}97}  \\\\\n",
      "\\pie{} ($n = 128$) & &  \\\\\n",
      "\\mf{}              &  37.4\\;\\textcolor{dark-gray}{$\\pm$\\;0.2} & \\textbf{ 830}\\;\\textcolor{dark-gray}{$\\pm$\\;\\hphantom{0}\\hphantom{0}5}  \\\\\n",
      "\\mf{} ($n = 128$)  &  37.2\\;\\textcolor{dark-gray}{$\\pm$\\;0.0} & 1645\\;\\textcolor{dark-gray}{$\\pm$\\;\\hphantom{0}\\hphantom{0}0}  \\\\\n",
      "\\mfe{}             &  35.8\\;\\textcolor{dark-gray}{$\\pm$\\;0.4} &  991\\;\\textcolor{dark-gray}{$\\pm$\\;\\hphantom{0}\\hphantom{0}4}  \\\\\n",
      "\\mfe{} ($n = 128$) & &  \\\\\n"
     ]
    }
   ],
   "source": [
    "print_results(latex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.12582888, 33.56935076, 33.12149346],\n",
       "       [72.60346539, 87.62884596, 66.76780555],\n",
       "       [        nan,         nan,         nan],\n",
       "       [37.89893445, 36.85327462, 37.34314453],\n",
       "       [37.19593512,         nan,         nan],\n",
       "       [35.78891746, 36.7025036 , 35.05215865],\n",
       "       [        nan,         nan,         nan]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gen_fids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
